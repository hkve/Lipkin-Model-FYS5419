\subsection{Toy models}
Going back to \cref{fig:res:changing_character} we see the classical example of level crossing in two-level systems. The phenomenon gets its name because in a plot of energy versus interaction strength, the energy levels appear to cross or avoid crossing each other, depending on the specific parameters and interactions involved, as seen. Taking a look at the coefficients, we see that for small interaction strengths $\lambda$, the ground state and excited state are almost purely dominated by $\ket{0}$ and $\ket{1}$ respectively. Increasing $\lambda$, the domination is less and less present. This continues until we reach $\lambda = 2/3$, where the ground state energy is maximal and excitation energy minimal. Moving past  $\lambda = 2/3$ results in the ground state being dominated by $\ket{1}$ and the excited state by $\ket{0}$, meaning that the states has change or swapped character.

\subsection{Entropy}
\begin{figure}
    \centering
    \includegraphics[scale=0.5]{figs/Eig_lmd.pdf}
    \caption{The eigenvalues of the interaction and non-interaction Hamiltonian, as a function of connection strength $\lambda$.}
    \label{fig:eig_lmd}
\end{figure}
\begin{figure}
    \centering
    \begin{subfigure}[b]{\linewidth}
        \includegraphics[width=\linewidth]{figs/RDM_0.3.PNG}
        \caption{The reduced density matrix of $\rho_a$ and $\rho_b$ for a interaction strength of $\lambda=0.3$}
         \label[fig]{fig:state_bois_1}
    \end{subfigure}
    \begin{subfigure}[b]{\linewidth}
        \includegraphics[width=\linewidth]{figs/RDM_0.5.PNG}
        \caption{The reduced density matrix of $\rho_a$ and $\rho_b$ for a interction strength of $\lambda=0.5$}
        \label[fig]{fig:state_bois_2}

    \end{subfigure}
    
\end{figure}

The entropy in Fig. (\ref{fig:entropy}) has an initial contribution which increases slower, before taking a leap for a connection strength of $\lambda \approx 0.4$. This is probably a jump corresponding to a system being slightly interacting into being entangled. The entanglement further increases before converging around $\lambda \approx 1.3$. Studying Fig(\ref{fig:eig_lmd}) we can extract some information, seeing as the first jump is correlated with the eigenvalues of the interaction Hamiltonian overcoming the second lowest eigenvalues. The convergence can be interpreted as the interaction energy overcoming the higher eigenvalues of the non-interaction Hamiltonian.
\newline\newline
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figs/bloch_entropy_lmd_2.PNG}
    \caption{The Bloch-spheres of the two qubits given $\lambda = 2$. }
    \label{fig:bloch_entropy}
\end{figure}
From Figs. (\ref{fig:state_bois1}) and (\ref{fig:state_bois_2}) the situation of the first spike in increased entropy from Fig. (\ref{fig:entropy}) is visualized through the diagonal of the reduced density matrices of the two sub-systems. It is apparent that there occurs a switch around $\lambda = 0.4$ where the reduced density matrices swaps from being in the state $$\rho_a(\lambda = 0.3) = c_1 \ket{0}\bra{0} \xrightarrow{} \rho_a(\lambda = 0.5) = c_2 \ket{1}\bra{1}$$
There is a similar occurence in the reduced density matrix  of $\rho_b$. These are not pure states, implicated by the trace of the diagonal, but the system of $\rho_a$ is more diagonalized, which makes it stricter in the outcomes of its entanglement, whereas $\rho_b$ has low occurrences along the diagonal, implicating that there are larger mixtures of states, which is more ideal for entanglement. Thus implicating the higher entropy for $\rho_b$ in Fig. (\ref{fig:entropy}). This is further emphasized when studying Fig(\ref{fig:bloch_entropy}). Here the connection strength dominates, which is indicated by the "weak" amplitude of the density matrices of the two states, which implies a superposition of states. These have higher entanglement than pure states which have amplitudes on the vectors stretching to the sphere. \newline\newline


\subsection{Lipkin Model}
From \cref{fig:res:Lipkin_N2_vary_v} we see good agreement between diagonalization and VQE. There were little trouble with convergence and precise results were obtained after just 30 iterations. The variability between runs were also minuscule, except when running for less than 30 iterations. It is also clear that VQE beats both HF and RPA consistently for the range of interaction strengths. 

Moving on to the four particle case from \cref{fig:res:Lipkin_N4_vary_v}, the precision of the results decreases. The two qbit scheme making use of the $W=0$ symmetry still shows excellent agreement with the diagonalization, but the larger four qbit scheme performs worse. This was the case despite increasing the number of iterations to 1000. Still, the four qbit results outperformed both HF and RPA for all except two interaction strengths, but showed some variability in results across identical runs. We hypothesize multiple reasons for this. Firstly, the number of Pauli string from \cref{eq:met:lipkin_N4_dumb} is 16 compared to the encoding from \cref{eq:met:lipkin_N4_smart_hamiltonian} only containing 6. We are therefor reliant on good estimates of Pauli string expectation values for more terms. If one or more of these estimates are poor for one iteration, the gradient estimate or the energy evaluation itself could be erroneously, resulting in slower converge. Intertwined with this is the sice of the parameter space which is twice as large for the four qbit case. Optimization here is harder and could hinder the convergence of the VQE. The $RY$ ansatz could of course also be too naive, restricting to only real amplitudes. Various different approaches are present in the literature, for instance the popular Unitary Coupled Cluster \citep{peruzzoVariationalEigenvalueSolver2014} being one of the gold standards in quantum chemistry. 
The runtime also increased with more qbits as expected. This is a clear indication that spending time reducing the number of Pauli strings by considering the symmetries of the system at hand is a worthwhile task.

When lifting the $W=0$ restriction, such as we saw in \cref{fig:res:lipkin_N4_vw_grid_VQE}, the convergence trouble was more apparent. For low $W$ values, the VQE outperformed both HF and RPA from \cref{fig:res:lipkin_N4_vw_grid_HF} and \cref{fig:res:lipkin_N4_vw_grid_RPA} respectively. For $V\to\epsilon$ but still $W \ll \epsilon$ some runs ended at $\sim 30\%$ relative error, but mostly the ground state was accurately estimated. Considering low $V$ values, accurate results can be seen up until $W \approx \epsilon/2$, before convergence reduces. The middle regions $W,V \in [0,\epsilon/3]$ seems to be the area where VQE would be clearly preferred over HF and RPA. This means we can handle systems where the interaction plays a relatively large part Hamiltonian, but not highly interactive systems.

The results from \cref{fig:res:lipkin_N4_vw_grid_VQE} are quite perforated, indicating that better results could be achieved by increasing the number of iterations and/or running each set of $(V,W)$ values multiple times. However since we are simulating a QC, simulating repeated VQE calculations for four qbit system for a range of different Hamiltonian would be too time-consuming for this work. Alternatively trying to find new clever ways to rewrite the Pauli strings \cref{eq:met:lipkin_N4_dumb} could be worthwhile, in addition to testing different ansatzes.      

Moving forward, calculations of other observable than the energy for ground state would be interesting. While the VQE is primarily focused on energy estimation, it can also yield approximate estimates for other observables, especially if they are closely related to the energy. This is because the optimized trial state tends to capture some aspects of the true state, which can influence the values of other observables. However, the accuracy of these estimates may vary depending on the specific system and observable of interest.
\begin{itemize}
    \item \st{Good correspondence for two qbit calculations. Beating both RPA and HF} 
    \item \st{Four qbits vary more. Can get differing results across runs} \begin{itemize}
        \item \st{More possible outcomes of measurements}
        \item \st{Harder to optimize due to larger parameter space. More interactions required?}
    \end{itemize}  
    \item \st{Also takes longer (due to more qbits). Emphasize using identities to shorten Pauli strings}.
    \item \st{Using the $W=0$ symmetry is good for four particles. Spending time on rewriting with symmetries in mind is a good idea.} 
    \item \st{Comment on general usable regions for $W/V$}
    \item \st{Comment on the "holes". Hinting to more optimization required. However still classical optimizer.} 
    \item \st{Compare with HF/RPA. Here the "beating" is less clear.}
    
\subsection{Future research}
The decision of the ansatz in Fig. (\ref{fig:ansatz}) seems a bit arbitrary, but is based on the ansatz in Hlatshwayo et al. (\cite{hlatshwayoSimulatingExcitedStates2022}). There could be possibilities in optimization by choosing a different ansatz. This would be a section of further research by delving into a review of VQE by Tilly et al. (\cite{VQE_review}). \comment{Dette har du noe om i Lipkin, gjerne fjern dette, likte bare kilden. }\newline 
Further research could look into other methods of optimization, other than the VQE algorithm, as it is a fairly simple model with restricted applicability. It could probably be extended to solving other optimization problems with minor tweaks or clever encoding. The Lipkin model is fairly limited when it comes to QC. This is a result of the angular momentum operators $j_+$ and $j_-$ are not unitary and thus not applicable to general QC. Thus other models could be further researched in order to not simplify the Hamiltonian by non-unitarity. These models become fairly complex quickly and involves heavier computational costs in order to construct and optimize. \comment{Mangler litt idé om fler ting å kunne ta opp her.} 
\end{itemize}
